{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfaddcd",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Bidirectional RNN\n",
    "Sentiment Analysis is the process of determining whether a piece of text is positive, negative, or neutral. It is widely used in social media monitoring, customer feedback and support, identification of derogatory tweets, product analysis, etc. Here we are going to build a Bidirectional RNN network to classify a sentence as either positive or negative using the sentiment-140 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04946fd2",
   "metadata": {},
   "source": [
    "## Step 1 - Importing the Dataset\n",
    "First, import the sentiment-140 dataset. Since sentiment-140 consists of about 1.6 million data samples, let’s only import a subset of it. The current dataset has half a million tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66291938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install wget\n",
    "import wget\n",
    "wget.download(\"https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip\")\n",
    "\n",
    "!unzip -n sentiment140-subset.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1f36f",
   "metadata": {},
   "source": [
    "## Step 2 - Loading the Dataset\n",
    "Install pandas library using the pip command. Later, import and read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eec593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('sentiment140-subset.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7caff94",
   "metadata": {},
   "source": [
    "## Step 3 - Reading the Dataset\n",
    "Print the data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767130ee",
   "metadata": {},
   "source": [
    "‘Text’ indicates the sentence and ‘polarity’, the sentiment attached to a sentence. ‘Polarity’ is either 0 or 1. 0 indicates negativity and 1 indicates positivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e88434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the total number of rows in the dataset and print the first 5 rows.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ce3de",
   "metadata": {},
   "source": [
    "## Step 4 - Processing the Dataset\n",
    "Since raw text is difficult to process by a neural network, we have to convert it into its corresponding numeric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do so, initialize your tokenizer by setting the maximum number \n",
    "# of words (features/tokens) that you would want to tokenize a sentence to\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "max_features = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f62831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tokenizer onto the text\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f95e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the resultant tokenizer to tokenize the text\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and lastly, pad the tokenized sequences to maintain the same length across all the input sequences\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, print the shape of the input vector.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf1052",
   "metadata": {},
   "source": [
    "## Step 4 - Create a Model\n",
    "Now, let’s create a Bidirectional RNN model. Use tf.keras.Sequential() to define the model. Add Embedding, SpatialDropout, Bidirectional, and Dense layers.\n",
    "\n",
    "* An embedding layer is the input layer that maps the words/tokenizers to a vector with embed_dim dimensions.\n",
    "* The spatial dropout layer is to drop the nodes so as to prevent overfitting. 0.4 indicates the probability with which the nodes have to be dropped.\n",
    "* The bidirectional layer is an RNN-LSTM layer with a size lstm_out.\n",
    "*  The dense is an output layer with 2 nodes (indicating positive and negative) and softmax activation function. Softmax helps in determining the probability of inclination of a text towards either positivity or negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbed_dim = 256\n",
    "lstm_out = 196\n",
    "\n",
    "# CODE HERE\n",
    "# Finally, attach categorical cross entropy loss and Adam optimizer functions to the model.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary to understand its layer stack.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104c626",
   "metadata": {},
   "source": [
    "## Step 5 - Initialize Train and Test Data\n",
    "Install and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e66b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7935676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-hot encoded representation of the output labels using the get_dummies() method.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c251aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the resultant 0 and 1 values with ‘Positive’ and ‘Negative’ respectively.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e932edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.values\n",
    "# Split train and test data using the train_test_split() method.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of train and test data.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba69e07",
   "metadata": {},
   "source": [
    "## Step 6 - Training the Model\n",
    "Call the model’s fit() method to train the model on train data for about 20 epochs with a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56503641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aed32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss graphs captured during the training process.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d4881",
   "metadata": {},
   "source": [
    "## Step 7 - Computing the Accuracy\n",
    "Print the prediction score and accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c97156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the prediction score and accuracy on test data.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c393ec",
   "metadata": {},
   "source": [
    "## Step 8 - Perform Sentiment Analysis\n",
    "Now's the time to predict the sentiment (positivity/negativity) for a user-given sentence. First, initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt = ['I do not recommend this product']\n",
    "#  Tokenize it.\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "# Pad it.\n",
    "twt = tf.keras.preprocessing.sequence.pad_sequences(twt, maxlen=X.shape[1], dtype='int32', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the sentiment by passing the sentence to the model we built.\n",
    "sentiment = model.predict(twt, batch_size=1)[0]\n",
    "print(sentiment)\n",
    "\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(y_arr[0])\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(y_arr[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
